{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geodesic Distances\n",
    "\n",
    "Using the [fdasrsf](https://fdasrsf-python.readthedocs.io/en/latest/) library, we compute the geodesic distances between pairs of open curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports / Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import tqdm\n",
    "from fdasrsf.geodesic import geod_sphere\n",
    "from tPCA_KarcherMean_AL import reparam,rescale,removeReps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = \"C:\\\\Users\\\\arian\\\\Downloads\\\\loutrophoros_for_distances.csv\" # Path to dataset.\n",
    "table = pd.read_csv(pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curves not open.\n",
      "Saved new version of open contours.\n"
     ]
    }
   ],
   "source": [
    "# Check if curves are open, if not, reparametrize.\n",
    "\n",
    "x = list(table[table['id']==table['id'].iloc[0]]['x'])\n",
    "y = list(table[table['id']==table['id'].iloc[0]]['y'])\n",
    "\n",
    "n = len(x)\n",
    "\n",
    "if (np.round(x[0],3) == np.round(x[-1],3)) and (np.round(y[0],3) == np.round(y[-1],3)):\n",
    "    print(\"Curves not open.\")\n",
    "    names = pd.unique(table['id'])\n",
    "    _x = []\n",
    "    _y = []\n",
    "    _types = []\n",
    "    _names = []\n",
    "    _pointorder = []\n",
    "    for nm in names:\n",
    "        table_id = table[table['id']==nm]\n",
    "        x = list(table_id['x'])[:-1]\n",
    "        y = list(table_id['y'])[:-1]\n",
    "        xr,yr = removeReps(x,y) # Just in case there are repeated points, we remove these.\n",
    "        newx,newy = reparam(xr,yr,npoints=n-1) # Repametrize the points so that we have the original number of points -1.\n",
    "        newx,newy = rescale(newx,newy) # Optional. Rescale between +-1.5. Comment out if not interested.\n",
    "        _x.extend(newx)\n",
    "        _y.extend(newy)\n",
    "        _types.extend([table_id['type'].iloc[0]]*(n-1))\n",
    "        _names.extend([nm]*(n-1))\n",
    "        _pointorder.extend(list(range(1,n)))\n",
    "        \n",
    "    table_old = deepcopy(table)\n",
    "    table = pd.DataFrame([_names,_x,_y,_pointorder,_types]).T\n",
    "    table = table.rename(columns={0:'id',1:'x',2:'y',3:'point_order',4:'type'})\n",
    "    del _names,_x,_y,_pointorder,_types\n",
    "    table.to_csv('new_contours_open.csv',index=False)\n",
    "    print(\"Saved new version of open contours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Distances by Group\n",
    "\n",
    "Here, we compute distance matrices per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_groups = np.unique(table['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = False # Set rescale = True, if you want to rescale curves to be within +-1.5 in the x,y axis.\n",
    "\n",
    "for group in all_groups:\n",
    "    filtered_table = table[table['type']==group]\n",
    "    names = np.unique(filtered_table['id'])\n",
    "    n = len(names)\n",
    "    distances_DP = np.zeros((n,n))\n",
    "    errors = []\n",
    "    print(\"Computing distance matrix for group: \"+str(group))\n",
    "    for i in tqdm.tqdm(range(0,n)):\n",
    "        x1 = list(filtered_table[filtered_table['id']==names[i]]['x'])\n",
    "        y1 = list(filtered_table[filtered_table['id']==names[i]]['y'])\n",
    "        if rescale == True:\n",
    "            x1,y1 = rescale_curve(np.array(x1),np.array(y1))\n",
    "        beta1 = np.column_stack([x1,y1]).T\n",
    "        for j in range(i+1,n):\n",
    "            x2 = list(filtered_table[filtered_table['id']==names[j]]['x'])\n",
    "            y2 = list(filtered_table[filtered_table['id']==names[j]]['y'])\n",
    "            if rescale == True:\n",
    "                x2,y2 = rescale_curve(np.array(x2),np.array(y2))\n",
    "            beta2 = np.column_stack([x2,y2]).T\n",
    "            try:\n",
    "                d,_,_, = geod_sphere(beta1, beta2)\n",
    "            except:\n",
    "                try:\n",
    "                    d,_,_, = geod_sphere(beta2, beta1)\n",
    "                except:\n",
    "                    errors.append([i,j])\n",
    "                    d = 100000\n",
    "\n",
    "            distances_DP[i,j] = d\n",
    "            distances_DP[j,i] = d\n",
    "    dists_df = pd.DataFrame(distances_DP,index=names)\n",
    "    dists_df.columns = names\n",
    "    dists_df.index.name = 'id' \n",
    "    dists_df.to_csv('Open_SRVF_Distances_'+str(group)+'.csv')\n",
    "    print(\"Computed distances between \"+str(n)+\" contours, with \"+str(len(errors))+\" errors.\")\n",
    "    # np.save('errors_'+str(group)+'.npy',errors) # Uncomment this if you'd wish to save the errors.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Distances on Entire Dataset\n",
    "\n",
    "Here, we compute one distance matrix based on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:12<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed distances between 5 contours, with 0 errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "names = np.unique(table['id'])\n",
    "n = len(names)\n",
    "\n",
    "distances_DP = np.zeros((n,n))\n",
    "errors = []\n",
    "\n",
    "for i in tqdm.tqdm(range(0,n)):\n",
    "    x1 = list(table[table['id']==names[i]]['x'])\n",
    "    y1 = list(table[table['id']==names[i]]['y'])\n",
    "    if rescale == True:\n",
    "        x1,y1 = rescale_curve(np.array(x1),np.array(y1))\n",
    "    beta1 = np.column_stack([x1,y1]).T\n",
    "    for j in range(i+1,n):\n",
    "        x2 = list(table[table['id']==names[j]]['x'])\n",
    "        y2 = list(table[table['id']==names[j]]['y'])\n",
    "        if rescale == True:\n",
    "            x2,y2 = rescale_curve(np.array(x2),np.array(y2))\n",
    "        beta2 = np.column_stack([x2,y2]).T\n",
    "        try:\n",
    "            d,_,_, = geod_sphere(beta1, beta2)\n",
    "        except:\n",
    "            try:\n",
    "                d,_,_, = geod_sphere(beta2, beta1)\n",
    "            except:\n",
    "                errors.append([i,j])\n",
    "                d = 100000\n",
    "\n",
    "        distances_DP[i,j] = d\n",
    "        distances_DP[j,i] = d\n",
    "        \n",
    "    pd.DataFrame(distances_DP).to_csv('Open_SRVF_Distances_ongoing.csv') # Save CSV distance matrix as you go along.\n",
    "    # This is a precautionary step in case the program breaks, so that distances won't be deleted.\n",
    "    # Comment out this step if you don't wish to save at each iteration.\n",
    "\n",
    "dists_df = pd.DataFrame(distances_DP,index=names)\n",
    "dists_df.columns = names\n",
    "dists_df.index.name = 'id' \n",
    "dists_df.to_csv('Open_SRVF_Distances_All.csv')\n",
    "print(\"Computed distances between \"+str(n)+\" contours, with \"+str(len(errors))+\" errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
